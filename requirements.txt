pip install opencv-python pyautogui tensorflow numpy pillow keyboard

import cv2
import time
import os
import platform
import pyautogui
from inference_sdk import InferenceHTTPClient

# ==============================
# Roboflow API Setup
# ==============================
client = InferenceHTTPClient(
    api_url="https://serverless.roboflow.com",
    api_key="9hOl5qU46mp0hE5rdlKg"  # <- paste your key here
)

workspace_name = "sankar-pz6eq"   
workflow_id = "detect-and-classify-4       


# ==============================
# Helper: Sleep/Shutdown
# ==============================
def sleep_system():
    os_name = platform.system()
    if os_name == "Windows":
        os.system("rundll32.exe powrprof.dll,SetSuspendState 0,1,0")
    elif os_name == "Darwin":  # macOS
        os.system("pmset sleepnow")
    elif os_name == "Linux":
        os.system("systemctl suspend")
    else:
        print("Unsupported OS for sleep command.")

# ==============================
# Webcam Setup
# ==============================
cap = cv2.VideoCapture(0)
eye_closed_start = None

while True:
    ret, frame = cap.read()
    if not ret:
        break

    frame = cv2.flip(frame, 1)  # mirror effect

    # Save temp frame to send to API
    temp_path = "temp.jpg"
    cv2.imwrite(temp_path, frame)

    # Get prediction from Roboflow
    result = client.run_workflow(
        workspace_name=workspace_name,
        workflow_id=workflow_id,
        images={"image": temp_path},
        use_cache=True
    )

    # Parse predictions
    if "predictions" in result and result["predictions"]:
        for pred in result["predictions"]:
            label = pred["class"].lower()
            conf = pred["confidence"]

            cv2.putText(frame, f"{label} ({conf*100:.1f}%)",
                        (10, 30), cv2.FONT_HERSHEY_SIMPLEX,
                        1, (0, 255, 0), 2)

            # === Yawn detection ===
            if label == "yawn" and conf > 0.85:
                print("[ACTION] Yawn detected → Pressing Space")
                pyautogui.press("space")
                time.sleep(1)

            # === Eyes closed for >10 sec ===
            if label == "eyes_closed" and conf > 0.85:
                if eye_closed_start is None:
                    eye_closed_start = time.time()
                elif time.time() - eye_closed_start >= 10:
                    print("[ACTION] Eyes closed >10s → Sleeping system")
                    sleep_system()
                    break
            else:
                eye_closed_start = None

            # === Palm gesture ===
            if label == "palm" and conf > 0.85:
                print("[ACTION] Palm detected → Switching browser tab")
                pyautogui.hotkey("ctrl", "tab")
                time.sleep(1)

    # Show webcam
    cv2.imshow("Lazy Assistant - Roboflow", frame)

    # Exit if Q pressed
    if cv2.waitKey(1) & 0xFF == ord("q"):
        break

cap.release()
cv2.destroyAllWindows()
